{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Patimetria2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHf/wizF5kwCAXw6V7YOIj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc815c13b66b4dad9e2acec6aec553de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af41aa7b0b4a42b783d7f3a23492158f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9189e4ff16604eda8a6c7d309c134ea4",
              "IPY_MODEL_db9a801f5c114e12b55f8d4a870ac67a"
            ]
          }
        },
        "af41aa7b0b4a42b783d7f3a23492158f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9189e4ff16604eda8a6c7d309c134ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e3922b58394e41649d3d3b38c9a69817",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6884538058d4e7dbaf1ef73a88cca09"
          }
        },
        "db9a801f5c114e12b55f8d4a870ac67a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81d23a4add2f499aacd34654e381d582",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:04&lt;00:00, 123MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b830a4e82856413eaae639f06108e961"
          }
        },
        "e3922b58394e41649d3d3b38c9a69817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6884538058d4e7dbaf1ef73a88cca09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81d23a4add2f499aacd34654e381d582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b830a4e82856413eaae639f06108e961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mar3334/Patimetria/blob/main/Patimetria2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IsugSfCY_zE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11464bdb-a836-40a6-a17f-070fefbea591"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Xh-5LoycHuly",
        "outputId": "2f09dd63-a6cc-4b90-c8f0-8b40f9e19adb"
      },
      "source": [
        "!pip install torch==1.4.0 torchvision==0.5.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 753.4MB 15kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.0MB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.19.4)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchvision"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Eu9YeGwW4I0",
        "outputId": "9426b322-631c-4396-d19e-455895892635"
      },
      "source": [
        "#!git clone https://github.com/adambielski/siamese-triplet.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'siamese-triplet'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Total 146 (delta 0), reused 0 (delta 0), pack-reused 146\u001b[K\n",
            "Receiving objects: 100% (146/146), 12.61 MiB | 33.54 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eppi8CjtPagb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf970ea-1de0-459e-a1ff-429c40a606e1"
      },
      "source": [
        "!cp -rf /content/drive/MyDrive/siamese-triplet /content/drive/MyDrive/siamese-triplet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot copy a directory, '/content/drive/MyDrive/siamese-triplet', into itself, '/content/drive/MyDrive/siamese-triplet/siamese-triplet'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB-oh40GYmf8"
      },
      "source": [
        "import torch\r\n",
        "from torchvision import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJrOu9XLY03h"
      },
      "source": [
        "import sys\r\n",
        "sys.path.append('/content/drive/MyDrive/siamese-triplet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-clKeEwY1Ot",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "dc815c13b66b4dad9e2acec6aec553de",
            "af41aa7b0b4a42b783d7f3a23492158f",
            "9189e4ff16604eda8a6c7d309c134ea4",
            "db9a801f5c114e12b55f8d4a870ac67a",
            "e3922b58394e41649d3d3b38c9a69817",
            "d6884538058d4e7dbaf1ef73a88cca09",
            "81d23a4add2f499aacd34654e381d582",
            "b830a4e82856413eaae639f06108e961"
          ]
        },
        "outputId": "a921c463-29f9-4b87-958d-08e8e87241ae"
      },
      "source": [
        "from networks import VGGEmbeddingNet, EmbeddingNet, TripletNet\r\n",
        "vgg_model = VGGEmbeddingNet()\r\n",
        "emb_net = EmbeddingNet()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc815c13b66b4dad9e2acec6aec553de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLov0Ow3dEUk"
      },
      "source": [
        "vgg_model_pretrained = VGGEmbeddingNet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8_GcOwxY4QR"
      },
      "source": [
        "from duckies_dataset import DuckieDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLOX2DaaY-_Z"
      },
      "source": [
        "from torchvision import transforms\r\n",
        "from duckies_dataset import Rescale\r\n",
        "trans = transforms.Compose([Rescale(224),\r\n",
        "                            transforms.ToTensor()])\r\n",
        "\r\n",
        "duckie_dataset = DuckieDataset('/content/drive/MyDrive/train', transform= trans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B3BucKLZiR7",
        "outputId": "ed8257d4-19e4-456b-bcd1-f34f2187ef71"
      },
      "source": [
        "from datasets import TripletMNIST\r\n",
        "triplet_dataset = TripletMNIST(duckie_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld4nhSBNZmy8"
      },
      "source": [
        "from trainer import fit, train_epoch, test_epoch\r\n",
        "from datasets import TripletMNIST\r\n",
        "train_dataset = DuckieDataset(\"/content/drive/MyDrive/train\", transform= trans)\r\n",
        "test_dataset = DuckieDataset(\"/content/drive/MyDrive/train\", train=False, transform= trans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn2gkk-saRZq",
        "outputId": "6509e24c-9727-4ae0-b21a-bb4e96b7b140"
      },
      "source": [
        "import torch\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import torch.optim as optim\r\n",
        "from torch.autograd import Variable\r\n",
        "from losses import TripletLoss\r\n",
        "import numpy as np\r\n",
        "cuda = torch.cuda.is_available()\r\n",
        "%matplotlib inline\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "# Set up data loaders\r\n",
        "\r\n",
        "triplet_train_dataset = TripletMNIST(train_dataset) # Returns triplets of images\r\n",
        "triplet_test_dataset = TripletMNIST(test_dataset)\r\n",
        "batch_size = 32\r\n",
        "kwargs = {'num_workers': 8, 'pin_memory': True} if cuda else {}\r\n",
        "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\r\n",
        "\r\n",
        "triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\r\n",
        "\r\n",
        "# Set up the network and training parameters\r\n",
        "\r\n",
        "margin = 1.\r\n",
        "embedding_net = EmbeddingNet()\r\n",
        "model = TripletNet(vgg_model)\r\n",
        "if cuda:\r\n",
        "    model.cuda()\r\n",
        "loss_fn = TripletLoss(margin)\r\n",
        "lr = 1e-3\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\r\n",
        "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\r\n",
        "n_epochs = 10\r\n",
        "log_interval = 500"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk7ukB4ga3RO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd205b0-dd73-45e9-fb1a-fd03fff02170"
      },
      "source": [
        "fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: [0/1080 (0%)]\tLoss: 0.808462\n",
            "Epoch: 1/10. Train set: Average loss: 0.9710\n",
            "Epoch: 1/10. Validation set: Average loss: 0.9462\n",
            "Train: [0/1080 (0%)]\tLoss: 0.952875\n",
            "Epoch: 2/10. Train set: Average loss: 0.7757\n",
            "Epoch: 2/10. Validation set: Average loss: 0.4199\n",
            "Train: [0/1080 (0%)]\tLoss: 0.707611\n",
            "Epoch: 3/10. Train set: Average loss: 0.5420\n",
            "Epoch: 3/10. Validation set: Average loss: 0.5285\n",
            "Train: [0/1080 (0%)]\tLoss: 0.696592\n",
            "Epoch: 4/10. Train set: Average loss: 0.5330\n",
            "Epoch: 4/10. Validation set: Average loss: 0.4279\n",
            "Train: [0/1080 (0%)]\tLoss: 0.552867\n",
            "Epoch: 5/10. Train set: Average loss: 0.5257\n",
            "Epoch: 5/10. Validation set: Average loss: 0.5201\n",
            "Train: [0/1080 (0%)]\tLoss: 0.422226\n",
            "Epoch: 6/10. Train set: Average loss: 0.5120\n",
            "Epoch: 6/10. Validation set: Average loss: 0.4105\n",
            "Train: [0/1080 (0%)]\tLoss: 0.343924\n",
            "Epoch: 7/10. Train set: Average loss: 0.4788\n",
            "Epoch: 7/10. Validation set: Average loss: 0.4042\n",
            "Train: [0/1080 (0%)]\tLoss: 0.511406\n",
            "Epoch: 8/10. Train set: Average loss: 0.3987\n",
            "Epoch: 8/10. Validation set: Average loss: 0.3727\n",
            "Train: [0/1080 (0%)]\tLoss: 0.381048\n",
            "Epoch: 9/10. Train set: Average loss: 0.4177\n",
            "Epoch: 9/10. Validation set: Average loss: 0.3614\n",
            "Train: [0/1080 (0%)]\tLoss: 0.265617\n",
            "Epoch: 10/10. Train set: Average loss: 0.3823\n",
            "Epoch: 10/10. Validation set: Average loss: 0.3679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF26aefvTNlk"
      },
      "source": [
        "# Define functions to extract embeddings using diferent datasets\r\n",
        "def extract_embeddings(dataset, model, dims = 1024, opt = None):\r\n",
        "    with torch.no_grad():\r\n",
        "        model.eval()\r\n",
        "        embeddings = np.zeros((len(dataset), dims))\r\n",
        "        labels = list()\r\n",
        "        for k, it_ in enumerate(dataset):\r\n",
        "            images = it_[0].unsqueeze_(0)\r\n",
        "            images = images.cuda()\r\n",
        "            target = it_[1]\r\n",
        "            if opt is None:\r\n",
        "                aux = model.get_embedding(images).data.cpu().numpy()\r\n",
        "            else:\r\n",
        "                aux = model.get_embedding(images, opt).data.cpu().numpy()\r\n",
        "            embeddings[k] = aux.reshape(1, dims)\r\n",
        "            labels.append(target)\r\n",
        "    return embeddings, labels\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGORG9c1Twos"
      },
      "source": [
        "embeddings, labels = extract_embeddings(test_dataset, vgg_model, dims = 512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkUr7sZETvX-",
        "outputId": "9df62692-9584-483c-e53d-2ef34dec5e57"
      },
      "source": [
        "'''\r\n",
        "emb1 = embeddings[-1,:]\r\n",
        "print(emb1.shape)\r\n",
        "for i in range(embeddings.shape[0]):\r\n",
        "    emb2 = embeddings[i,:]\r\n",
        "    dist = np.sum((emb2 - emb1)**2)\r\n",
        "    print(dist, labels[i])\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512,)\n",
            "1.6502837951017366 tensor(228.)\n",
            "1.8217226019836312 tensor(228.)\n",
            "1.970004959507878 tensor(229.)\n",
            "0.9628877005756225 tensor(229.)\n",
            "1.4609063977398042 tensor(229.)\n",
            "1.4613784141557664 tensor(229.)\n",
            "1.8781259397282728 tensor(230.)\n",
            "1.2236530895505244 tensor(230.)\n",
            "1.798596555973646 tensor(230.)\n",
            "1.7364517478788835 tensor(230.)\n",
            "1.8507907801226602 tensor(231.)\n",
            "1.6892059898605782 tensor(231.)\n",
            "1.8354687488457837 tensor(231.)\n",
            "1.8880668121763542 tensor(232.)\n",
            "1.9540483111439266 tensor(232.)\n",
            "1.7913181982568307 tensor(232.)\n",
            "1.9540613625960606 tensor(232.)\n",
            "1.9540527338551892 tensor(232.)\n",
            "1.3281735956217426 tensor(233.)\n",
            "1.6255817298604536 tensor(233.)\n",
            "1.6880882394897996 tensor(233.)\n",
            "1.9366967344248587 tensor(233.)\n",
            "0.2859212286321504 tensor(234.)\n",
            "0.12068297838695373 tensor(234.)\n",
            "0.5243246085165081 tensor(234.)\n",
            "0.08158551760496088 tensor(234.)\n",
            "1.9521709227504003 tensor(235.)\n",
            "1.1640232504269765 tensor(235.)\n",
            "1.5296535613548616 tensor(235.)\n",
            "1.778552412895722 tensor(235.)\n",
            "1.954044980606761 tensor(236.)\n",
            "1.9540452811257538 tensor(236.)\n",
            "1.9550384223319048 tensor(236.)\n",
            "1.954045005667594 tensor(236.)\n",
            "1.8476697252707919 tensor(237.)\n",
            "1.6895116747214673 tensor(237.)\n",
            "1.873111518465357 tensor(237.)\n",
            "1.6812586044304356 tensor(237.)\n",
            "1.7928380617536719 tensor(237.)\n",
            "1.790750673254319 tensor(237.)\n",
            "0.9759294183935128 tensor(238.)\n",
            "0.9906164396596331 tensor(238.)\n",
            "1.0469845062645544 tensor(238.)\n",
            "1.0664315458770068 tensor(238.)\n",
            "1.281634437868191 tensor(238.)\n",
            "1.928194862868887 tensor(239.)\n",
            "1.9495535634464742 tensor(239.)\n",
            "1.958817907496283 tensor(239.)\n",
            "1.888813530368392 tensor(239.)\n",
            "1.9102876938805147 tensor(239.)\n",
            "1.9523959386120397 tensor(239.)\n",
            "1.9538776675263063 tensor(240.)\n",
            "1.954045383289579 tensor(240.)\n",
            "1.9540452935036103 tensor(240.)\n",
            "1.954045272852361 tensor(240.)\n",
            "0.7490404993730796 tensor(241.)\n",
            "0.7490404993730796 tensor(241.)\n",
            "0.3648487783302844 tensor(241.)\n",
            "0.30137301365384483 tensor(241.)\n",
            "0.2662298974985282 tensor(241.)\n",
            "0.9761582323034423 tensor(241.)\n",
            "1.189308800302469 tensor(241.)\n",
            "1.0758408018970222 tensor(241.)\n",
            "0.7448020562952358 tensor(241.)\n",
            "0.5845633036288893 tensor(241.)\n",
            "1.2276080408354293 tensor(241.)\n",
            "0.964743345510451 tensor(242.)\n",
            "1.7240635831242366 tensor(242.)\n",
            "0.4074582038089948 tensor(242.)\n",
            "1.113705245814326 tensor(242.)\n",
            "0.32153511217836545 tensor(242.)\n",
            "1.9693275525371723 tensor(243.)\n",
            "1.9693275525371723 tensor(243.)\n",
            "1.6251981241817082 tensor(243.)\n",
            "1.6251981241817082 tensor(243.)\n",
            "1.6747299503626336 tensor(243.)\n",
            "1.6747299503626336 tensor(243.)\n",
            "1.843837793003647 tensor(243.)\n",
            "1.843837793003647 tensor(243.)\n",
            "1.6249400297502636 tensor(244.)\n",
            "1.3882025078546292 tensor(244.)\n",
            "1.4643784383183753 tensor(244.)\n",
            "1.2976197194919232 tensor(244.)\n",
            "1.491618521705205 tensor(244.)\n",
            "1.8619621309771377 tensor(245.)\n",
            "0.9708569997526435 tensor(245.)\n",
            "0.7912421953520613 tensor(245.)\n",
            "0.3754669958113631 tensor(246.)\n",
            "0.3171430134699059 tensor(246.)\n",
            "0.21013419916671694 tensor(246.)\n",
            "0.25658313827047646 tensor(246.)\n",
            "1.617175278183506 tensor(246.)\n",
            "1.6168306453798758 tensor(246.)\n",
            "0.35030756626468385 tensor(246.)\n",
            "1.5928313426491183 tensor(246.)\n",
            "1.642793140068706 tensor(246.)\n",
            "1.733755732955184 tensor(246.)\n",
            "1.9540541209572282 tensor(247.)\n",
            "1.9540934362560858 tensor(247.)\n",
            "1.9542586440854401 tensor(247.)\n",
            "1.9540833640401307 tensor(247.)\n",
            "1.862017518744945 tensor(248.)\n",
            "1.456339555029933 tensor(248.)\n",
            "1.7965338422672679 tensor(248.)\n",
            "1.9569922717603738 tensor(248.)\n",
            "0.7549914488976839 tensor(249.)\n",
            "1.0811046975343133 tensor(249.)\n",
            "1.2473842482488962 tensor(249.)\n",
            "1.1527886824118398 tensor(249.)\n",
            "1.7370047988063528 tensor(250.)\n",
            "1.7399203098824432 tensor(250.)\n",
            "1.8340941600315808 tensor(250.)\n",
            "1.4661422873425973 tensor(250.)\n",
            "1.4966361549606346 tensor(250.)\n",
            "1.8640594088430604 tensor(251.)\n",
            "1.783444485337188 tensor(251.)\n",
            "1.7259167591651698 tensor(251.)\n",
            "1.6340605285361085 tensor(251.)\n",
            "1.5655391554393137 tensor(252.)\n",
            "1.5456488156194872 tensor(252.)\n",
            "0.9811216156207507 tensor(252.)\n",
            "0.8517086791179304 tensor(252.)\n",
            "1.1280812355137741 tensor(252.)\n",
            "0.9039380283746793 tensor(252.)\n",
            "1.5727680184784574 tensor(253.)\n",
            "1.0877202493751275 tensor(253.)\n",
            "0.7091242489701123 tensor(253.)\n",
            "1.7431692854948904 tensor(253.)\n",
            "1.9154890477527304 tensor(254.)\n",
            "1.5626566302518086 tensor(254.)\n",
            "1.8468975263459788 tensor(254.)\n",
            "1.5369105505259395 tensor(254.)\n",
            "1.867508977942486 tensor(255.)\n",
            "1.5793065867840475 tensor(255.)\n",
            "1.382805205341191 tensor(255.)\n",
            "1.8592464186921926 tensor(255.)\n",
            "0.8943749082246316 tensor(256.)\n",
            "0.9083653481545031 tensor(256.)\n",
            "0.8318488533963304 tensor(256.)\n",
            "0.8584930008999824 tensor(256.)\n",
            "0.6802765025953862 tensor(257.)\n",
            "0.24296640058164043 tensor(257.)\n",
            "0.08676044780463518 tensor(257.)\n",
            "0.08727760801043809 tensor(257.)\n",
            "1.5116188155875148 tensor(258.)\n",
            "0.9831609552061116 tensor(258.)\n",
            "1.4478912394931782 tensor(258.)\n",
            "1.3659013432269709 tensor(258.)\n",
            "0.40294319171164245 tensor(259.)\n",
            "0.2989427796823712 tensor(259.)\n",
            "0.22462922967054885 tensor(259.)\n",
            "0.22327023022749343 tensor(259.)\n",
            "1.5978931857918783 tensor(260.)\n",
            "1.4479308236023312 tensor(260.)\n",
            "0.9009060035686218 tensor(260.)\n",
            "1.8113611164060865 tensor(261.)\n",
            "1.4667333555303337 tensor(261.)\n",
            "0.6459296927500043 tensor(261.)\n",
            "1.94726384630864 tensor(261.)\n",
            "0.45171436412271815 tensor(262.)\n",
            "0.2202248491296363 tensor(262.)\n",
            "0.23446970829107322 tensor(262.)\n",
            "0.17930847349795198 tensor(262.)\n",
            "0.24899191327792267 tensor(263.)\n",
            "0.27259846325733367 tensor(263.)\n",
            "0.2410365223583961 tensor(263.)\n",
            "0.3057747150277722 tensor(263.)\n",
            "0.3610055914655368 tensor(264.)\n",
            "0.36132147395618375 tensor(264.)\n",
            "0.6200958663736698 tensor(265.)\n",
            "0.6195395670645312 tensor(265.)\n",
            "1.9540612476463284 tensor(266.)\n",
            "1.2615219520441667 tensor(266.)\n",
            "1.9541999413169198 tensor(266.)\n",
            "0.6649535792667092 tensor(266.)\n",
            "0.6674861067080229 tensor(267.)\n",
            "0.7664968066693725 tensor(267.)\n",
            "0.48986865455173967 tensor(267.)\n",
            "0.5774598043664692 tensor(267.)\n",
            "0.030561807519599603 tensor(268.)\n",
            "0.0891794128642662 tensor(268.)\n",
            "0.3275376076363472 tensor(268.)\n",
            "1.0334548751450252 tensor(268.)\n",
            "0.9849044875074682 tensor(269.)\n",
            "0.7496285070136958 tensor(269.)\n",
            "0.7628230007449679 tensor(269.)\n",
            "0.9890856053757973 tensor(269.)\n",
            "0.36123324594807044 tensor(270.)\n",
            "1.9623693699467164 tensor(270.)\n",
            "1.9371540130178078 tensor(270.)\n",
            "1.2793273082353813 tensor(270.)\n",
            "1.9344967845984542 tensor(271.)\n",
            "1.8613368359589386 tensor(271.)\n",
            "1.6488034830041352 tensor(271.)\n",
            "1.6410788779518952 tensor(271.)\n",
            "1.2924408443369688 tensor(272.)\n",
            "0.6806569102407203 tensor(272.)\n",
            "0.1875959232272723 tensor(272.)\n",
            "0.1297451744717692 tensor(272.)\n",
            "1.6275526228139454 tensor(273.)\n",
            "1.5735027070418184 tensor(273.)\n",
            "1.7667534168804082 tensor(273.)\n",
            "1.4958336543612343 tensor(273.)\n",
            "1.6956553671089265 tensor(274.)\n",
            "1.853437542485449 tensor(274.)\n",
            "1.9768218426941424 tensor(274.)\n",
            "1.9361383042025175 tensor(275.)\n",
            "1.950539005371444 tensor(275.)\n",
            "1.9367943374999634 tensor(275.)\n",
            "1.9541741835095405 tensor(275.)\n",
            "0.14894316208339226 tensor(276.)\n",
            "1.0334874929727729 tensor(276.)\n",
            "1.562097130424164 tensor(276.)\n",
            "0.7395064004922012 tensor(276.)\n",
            "1.3692298373368001 tensor(277.)\n",
            "1.9686459694062564 tensor(277.)\n",
            "1.7580328251756654 tensor(277.)\n",
            "1.4023250141868524 tensor(277.)\n",
            "0.8747836767648965 tensor(278.)\n",
            "1.3521302063883243 tensor(278.)\n",
            "0.8747836767648965 tensor(278.)\n",
            "0.22647075806052283 tensor(278.)\n",
            "0.6508862545386862 tensor(279.)\n",
            "0.6491072634357463 tensor(279.)\n",
            "1.6813562534951376 tensor(279.)\n",
            "0.7277892769284313 tensor(279.)\n",
            "0.6440228519849158 tensor(279.)\n",
            "0.6352388283985646 tensor(279.)\n",
            "1.96960790233819 tensor(280.)\n",
            "1.9214705830440355 tensor(280.)\n",
            "1.909248372258952 tensor(280.)\n",
            "1.9139625962376687 tensor(280.)\n",
            "1.4746962283104406 tensor(281.)\n",
            "1.6909437047336424 tensor(281.)\n",
            "1.6827801500804767 tensor(281.)\n",
            "1.6376683392810891 tensor(281.)\n",
            "1.2733456401243148 tensor(282.)\n",
            "0.2871256497329214 tensor(282.)\n",
            "0.8620223153126052 tensor(282.)\n",
            "0.8096620092424406 tensor(283.)\n",
            "0.7043626230553004 tensor(283.)\n",
            "0.2252508173111705 tensor(283.)\n",
            "0.5593651723281811 tensor(283.)\n",
            "0.37845640369039185 tensor(284.)\n",
            "0.8061251772845563 tensor(284.)\n",
            "0.2532937679309879 tensor(284.)\n",
            "0.036380888430614725 tensor(284.)\n",
            "0.0 tensor(284.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uslR2-XydMRY"
      },
      "source": [
        "embeddings1, labels1 = extract_embeddings(test_dataset, vgg_model_pretrained.cuda(), dims = 512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2iqp76-df9S",
        "outputId": "7f86fe00-a07f-4dec-c0eb-3b580bea1ec8"
      },
      "source": [
        "'''\r\n",
        "emb1 = embeddings1[-1,:]\r\n",
        "print(emb1.shape)\r\n",
        "for i in range(embeddings1.shape[0]):\r\n",
        "    emb2 = embeddings1[i,:]\r\n",
        "    dist = np.sum((emb2 - emb1)**2)\r\n",
        "    print(dist, labels1[i])\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512,)\n",
            "0.630583970944256 tensor(228.)\n",
            "0.5489316875561194 tensor(228.)\n",
            "0.5401648445001825 tensor(229.)\n",
            "0.579095291802384 tensor(229.)\n",
            "0.3966684128232094 tensor(229.)\n",
            "0.4195389272663902 tensor(229.)\n",
            "0.43249176994107597 tensor(230.)\n",
            "0.519822967579026 tensor(230.)\n",
            "0.35402580539168627 tensor(230.)\n",
            "0.36921421131803506 tensor(230.)\n",
            "0.5761297998356337 tensor(231.)\n",
            "0.5503901105303631 tensor(231.)\n",
            "0.5043408889681327 tensor(231.)\n",
            "0.8570932861951437 tensor(232.)\n",
            "0.6134906876702113 tensor(232.)\n",
            "0.8036465265789257 tensor(232.)\n",
            "0.5703406317007375 tensor(232.)\n",
            "0.5456899517690402 tensor(232.)\n",
            "0.8322622080529798 tensor(233.)\n",
            "0.7355504444094727 tensor(233.)\n",
            "0.6496333637506815 tensor(233.)\n",
            "0.6804755234783255 tensor(233.)\n",
            "0.6332883895895459 tensor(234.)\n",
            "0.44739782683984713 tensor(234.)\n",
            "0.5729899107555607 tensor(234.)\n",
            "0.46852782932405873 tensor(234.)\n",
            "1.2457919125829382 tensor(235.)\n",
            "0.9145934490328036 tensor(235.)\n",
            "0.89636740990823 tensor(235.)\n",
            "0.7484997093079961 tensor(235.)\n",
            "0.865921473643684 tensor(236.)\n",
            "0.7508841290629188 tensor(236.)\n",
            "1.1178323291353063 tensor(236.)\n",
            "0.7336574411254655 tensor(236.)\n",
            "0.6939865365435587 tensor(237.)\n",
            "0.6582845498972263 tensor(237.)\n",
            "0.7661482749951285 tensor(237.)\n",
            "0.6550757128094788 tensor(237.)\n",
            "0.6136925307298813 tensor(237.)\n",
            "0.6749154450253484 tensor(237.)\n",
            "0.5229940763831372 tensor(238.)\n",
            "0.5221929832198844 tensor(238.)\n",
            "0.6816427006896872 tensor(238.)\n",
            "0.7045194344772718 tensor(238.)\n",
            "0.4856615966879524 tensor(238.)\n",
            "0.42246916106924626 tensor(239.)\n",
            "0.5716303483432347 tensor(239.)\n",
            "0.564571577200179 tensor(239.)\n",
            "0.6453706623168323 tensor(239.)\n",
            "0.4891825706477747 tensor(239.)\n",
            "0.6770574760567012 tensor(239.)\n",
            "0.907038036904179 tensor(240.)\n",
            "0.687708239761976 tensor(240.)\n",
            "0.7698058895850644 tensor(240.)\n",
            "0.7014953855553371 tensor(240.)\n",
            "0.4174011205447026 tensor(241.)\n",
            "0.4174011205447026 tensor(241.)\n",
            "0.5452886885415622 tensor(241.)\n",
            "0.5438087667032042 tensor(241.)\n",
            "0.40371236761546436 tensor(241.)\n",
            "0.40483530703975207 tensor(241.)\n",
            "0.4107993219988702 tensor(241.)\n",
            "0.3769275746690802 tensor(241.)\n",
            "0.4418331252076716 tensor(241.)\n",
            "0.3892622778814388 tensor(241.)\n",
            "0.40652981786485 tensor(241.)\n",
            "0.6575428467939761 tensor(242.)\n",
            "0.6500117882828798 tensor(242.)\n",
            "0.46157980140209665 tensor(242.)\n",
            "0.6778811733081869 tensor(242.)\n",
            "0.5881546439404297 tensor(242.)\n",
            "0.49759941369068483 tensor(243.)\n",
            "0.49759941369068483 tensor(243.)\n",
            "0.6873095584193734 tensor(243.)\n",
            "0.6873095584193734 tensor(243.)\n",
            "0.5700425313094488 tensor(243.)\n",
            "0.5700425313094488 tensor(243.)\n",
            "0.4089229238150574 tensor(243.)\n",
            "0.4089229238150574 tensor(243.)\n",
            "0.7057692470253589 tensor(244.)\n",
            "0.5710349646598958 tensor(244.)\n",
            "0.6380659664841692 tensor(244.)\n",
            "0.6028250797013267 tensor(244.)\n",
            "0.5866260795876743 tensor(244.)\n",
            "0.48520666640520127 tensor(245.)\n",
            "0.42976148188225827 tensor(245.)\n",
            "0.4652754333226534 tensor(245.)\n",
            "0.5005530269770798 tensor(246.)\n",
            "0.5281838624305695 tensor(246.)\n",
            "0.3775933042486642 tensor(246.)\n",
            "0.3207742324704416 tensor(246.)\n",
            "0.6459611628350117 tensor(246.)\n",
            "0.6036041038124108 tensor(246.)\n",
            "0.39328317249111033 tensor(246.)\n",
            "0.3128399067114175 tensor(246.)\n",
            "0.5159477079929868 tensor(246.)\n",
            "0.4794306968519916 tensor(246.)\n",
            "0.4408214488407468 tensor(247.)\n",
            "0.29971824866426433 tensor(247.)\n",
            "0.5649434655167511 tensor(247.)\n",
            "0.3315239693544253 tensor(247.)\n",
            "0.5168146209548132 tensor(248.)\n",
            "0.4719401641778479 tensor(248.)\n",
            "0.45823286608862285 tensor(248.)\n",
            "0.344018272233216 tensor(248.)\n",
            "0.5528720233326173 tensor(249.)\n",
            "0.48600386044610444 tensor(249.)\n",
            "0.329833050573439 tensor(249.)\n",
            "0.3898184418535777 tensor(249.)\n",
            "0.5844637722412018 tensor(250.)\n",
            "0.5840030715512572 tensor(250.)\n",
            "0.6234672081659325 tensor(250.)\n",
            "0.5893601671212046 tensor(250.)\n",
            "0.6632966110113727 tensor(250.)\n",
            "0.588568834892243 tensor(251.)\n",
            "0.6156670678531264 tensor(251.)\n",
            "0.5278174323126547 tensor(251.)\n",
            "0.602308345073645 tensor(251.)\n",
            "0.43500553831823763 tensor(252.)\n",
            "0.43633720262766384 tensor(252.)\n",
            "0.45969028541204704 tensor(252.)\n",
            "0.3941580107786987 tensor(252.)\n",
            "0.4857282937757216 tensor(252.)\n",
            "0.361756864798158 tensor(252.)\n",
            "0.5004343832898018 tensor(253.)\n",
            "0.44298338638090723 tensor(253.)\n",
            "0.46038919059473915 tensor(253.)\n",
            "0.3835478155353099 tensor(253.)\n",
            "0.6959606934066238 tensor(254.)\n",
            "0.4828536593036154 tensor(254.)\n",
            "0.4838024101865121 tensor(254.)\n",
            "0.5277658729149671 tensor(254.)\n",
            "0.5983800803378851 tensor(255.)\n",
            "0.47688877264235296 tensor(255.)\n",
            "0.459454196913485 tensor(255.)\n",
            "0.5269334830809183 tensor(255.)\n",
            "0.5950260212596499 tensor(256.)\n",
            "0.566343932032727 tensor(256.)\n",
            "0.49922510822649757 tensor(256.)\n",
            "0.3974712860604297 tensor(256.)\n",
            "0.5374767695967961 tensor(257.)\n",
            "0.6407185983462884 tensor(257.)\n",
            "0.3801975239278282 tensor(257.)\n",
            "0.415222024259567 tensor(257.)\n",
            "0.48945534273512176 tensor(258.)\n",
            "0.533546436727109 tensor(258.)\n",
            "0.36738630286149476 tensor(258.)\n",
            "0.37711679926777475 tensor(258.)\n",
            "0.512596723003196 tensor(259.)\n",
            "0.5256553894490439 tensor(259.)\n",
            "0.38023924104970697 tensor(259.)\n",
            "0.29570608403047594 tensor(259.)\n",
            "0.7106096643962299 tensor(260.)\n",
            "0.6245185004036151 tensor(260.)\n",
            "0.5838510828892969 tensor(260.)\n",
            "0.6493998140918169 tensor(261.)\n",
            "0.5146646952983974 tensor(261.)\n",
            "0.6501647349072113 tensor(261.)\n",
            "0.43101496809261425 tensor(261.)\n",
            "0.5022477004786468 tensor(262.)\n",
            "0.5225870560647037 tensor(262.)\n",
            "0.47141319033969425 tensor(262.)\n",
            "0.41420966462787573 tensor(262.)\n",
            "0.5398831169847724 tensor(263.)\n",
            "0.5243506096503545 tensor(263.)\n",
            "0.4137092683911471 tensor(263.)\n",
            "0.43399258812431085 tensor(263.)\n",
            "0.535860940845784 tensor(264.)\n",
            "0.5362186515953951 tensor(264.)\n",
            "0.601141229537492 tensor(265.)\n",
            "0.601864392596254 tensor(265.)\n",
            "0.5080322040370895 tensor(266.)\n",
            "0.6420692602282526 tensor(266.)\n",
            "0.4488770507303359 tensor(266.)\n",
            "0.3618987414300537 tensor(266.)\n",
            "0.5211558523285791 tensor(267.)\n",
            "0.5701064002546028 tensor(267.)\n",
            "0.4318981218527025 tensor(267.)\n",
            "0.4038064017992064 tensor(267.)\n",
            "0.6443103482175216 tensor(268.)\n",
            "0.4640685519499147 tensor(268.)\n",
            "0.42337802547847536 tensor(268.)\n",
            "0.36679371246010134 tensor(268.)\n",
            "0.6521279548002911 tensor(269.)\n",
            "0.6570812177956106 tensor(269.)\n",
            "0.6094452010331055 tensor(269.)\n",
            "0.49249354080580665 tensor(269.)\n",
            "0.5492397735693824 tensor(270.)\n",
            "0.4217788558389018 tensor(270.)\n",
            "0.3919072088910903 tensor(270.)\n",
            "0.49876621376850055 tensor(270.)\n",
            "0.507623620124856 tensor(271.)\n",
            "0.536548929800825 tensor(271.)\n",
            "0.43226284223187916 tensor(271.)\n",
            "0.4954321438780761 tensor(271.)\n",
            "0.6131280200174096 tensor(272.)\n",
            "0.5325429171881648 tensor(272.)\n",
            "0.39313990041798214 tensor(272.)\n",
            "0.4405205246349806 tensor(272.)\n",
            "0.5393550961986069 tensor(273.)\n",
            "0.43662223011309226 tensor(273.)\n",
            "0.43823101328234515 tensor(273.)\n",
            "0.41670990385904344 tensor(273.)\n",
            "0.41969826217174333 tensor(274.)\n",
            "0.4573670858015547 tensor(274.)\n",
            "0.48510978380328873 tensor(274.)\n",
            "0.5343503248201396 tensor(275.)\n",
            "0.40952343003327946 tensor(275.)\n",
            "0.4292132065698888 tensor(275.)\n",
            "0.43396841842032774 tensor(275.)\n",
            "0.42528309447787604 tensor(276.)\n",
            "0.3854896697523731 tensor(276.)\n",
            "0.6809164989388532 tensor(276.)\n",
            "0.3414032562542523 tensor(276.)\n",
            "0.56550198626485 tensor(277.)\n",
            "0.654182805510624 tensor(277.)\n",
            "0.622628842848973 tensor(277.)\n",
            "0.6869478594578423 tensor(277.)\n",
            "0.48443050103150764 tensor(278.)\n",
            "0.41459787713476626 tensor(278.)\n",
            "0.48443050103150764 tensor(278.)\n",
            "0.3397092142674924 tensor(278.)\n",
            "0.5220717769704719 tensor(279.)\n",
            "0.5228849106723557 tensor(279.)\n",
            "0.5057203310347667 tensor(279.)\n",
            "0.6356771092486366 tensor(279.)\n",
            "0.41627108881270647 tensor(279.)\n",
            "0.5508876752273818 tensor(279.)\n",
            "0.6656283794884733 tensor(280.)\n",
            "0.43266505845766967 tensor(280.)\n",
            "0.47702107256384224 tensor(280.)\n",
            "0.48074933297684463 tensor(280.)\n",
            "0.5474108115350835 tensor(281.)\n",
            "0.5593016964386028 tensor(281.)\n",
            "0.6067387886500509 tensor(281.)\n",
            "0.5037333081561484 tensor(281.)\n",
            "0.6021496957199624 tensor(282.)\n",
            "0.49416311338896457 tensor(282.)\n",
            "0.4425314939787284 tensor(282.)\n",
            "0.5922285301081502 tensor(283.)\n",
            "0.44782905520141364 tensor(283.)\n",
            "0.413386156110939 tensor(283.)\n",
            "0.3064579288467757 tensor(283.)\n",
            "0.568045103372948 tensor(284.)\n",
            "0.5256085014483143 tensor(284.)\n",
            "0.46458383212681975 tensor(284.)\n",
            "0.17493338818325552 tensor(284.)\n",
            "0.0 tensor(284.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUfuE4B2pnlI"
      },
      "source": [
        "from PIL import Image\r\n",
        "def n_closest_images(image, n=5):\r\n",
        "  img = Image.open(image)\r\n",
        "  img = trans(img)\r\n",
        "  emb_img = vgg_model(img.unsqueeze(0).cuda())\r\n",
        "  embedding_img = emb_img.data.cpu().numpy()\r\n",
        "  list_dist = []\r\n",
        "  list_labels = []\r\n",
        "  neat_list = []\r\n",
        "  label_ubication_list = []\r\n",
        "  for i in range(embeddings.shape[0]):\r\n",
        "    emb2 = embeddings[i,:]\r\n",
        "    dist = np.sum((emb2 - embedding_img)**2)\r\n",
        "    list_dist.append(dist)\r\n",
        "  neat_list[:] = list_dist\r\n",
        "  neat_list.sort()\r\n",
        "  for i in range(n):\r\n",
        "    position = list_dist.index(neat_list[i])\r\n",
        "    label_ubication = position - labels.index(labels[position])\r\n",
        "    label_ubication_list.append(label_ubication)\r\n",
        "    list_labels.append(labels[position])\r\n",
        "  print (neat_list[:n], list_labels, label_ubication_list)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYZvv4tkMwgC",
        "outputId": "bf72695e-86fb-4df7-c098-bf6fdaed03e6"
      },
      "source": [
        "n_closest_images(\"/content/drive/MyDrive/Patos/Lucas/PatoLucas.jpg\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01503039433636619, 0.015604701639392727, 0.019240022737123247, 0.020296860477561466, 0.022060672812869535] [tensor(281.), tensor(273.), tensor(281.), tensor(251.), tensor(273.)] [3, 1, 1, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "xss4D0iveoyb",
        "outputId": "11f0ac90-f132-40c2-8e9a-5782015a9332"
      },
      "source": [
        "'''\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "pato_lucas = Image.open(\"/content/drive/MyDrive/Patos/Lucas/PatoLucas.jpg\")\r\n",
        "pato_lucas = trans(pato_lucas)\r\n",
        "emb_pato_lucas = vgg_model(pato_lucas.unsqueeze(0).cuda())\r\n",
        "print (emb_pato_lucas.shape)\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom PIL import Image\\n\\npato_lucas = Image.open(\"/content/drive/MyDrive/Patos/Lucas/PatoLucas.jpg\")\\npato_lucas = trans(pato_lucas)\\nemb_pato_lucas = vgg_model(pato_lucas.unsqueeze(0).cuda())\\nprint (emb_pato_lucas.shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "lB37nLHYhByD",
        "outputId": "862cdfbf-e2d6-4ac8-cbee-99f884d9563a"
      },
      "source": [
        "'''\r\n",
        "emb1 = emb_pato_lucas.data.cpu().numpy()\r\n",
        "print(emb1.shape)\r\n",
        "for i in range(embeddings.shape[0]):\r\n",
        "    emb2 = embeddings[i,:]\r\n",
        "    dist = np.sum((emb2 - emb1)**2)\r\n",
        "    print(dist, labels[i])\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nemb1 = emb_pato_lucas.data.cpu().numpy()\\nprint(emb1.shape)\\nfor i in range(embeddings.shape[0]):\\n    emb2 = embeddings[i,:]\\n    dist = np.sum((emb2 - emb1)**2)\\n    print(dist, labels[i])\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKvbggd1htPG"
      },
      "source": [
        "#test_dataset.class_to_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSG-NKCsOH4g",
        "outputId": "a38d93d5-eced-4842-bf7f-ed2d97957669"
      },
      "source": [
        "lista = [1,1,2,3]\r\n",
        "lista.index(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}